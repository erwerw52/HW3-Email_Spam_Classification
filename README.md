# 垃圾郵件分類系統 - Phase 1

基於 Streamlit 和 scikit-learn 的智能垃圾郵件分類系統，提供實時分類、模型性能分析和數據可視化功能。參考老師範例設計，提供專業級的機器學習應用體驗。

## 🎯 功能特色

### 🎯 Live Inference - 實時推理
- **智能郵件輸入**: 支持手動輸入和範例選擇
- **隨機範例生成**: 🚨 垃圾郵件、✅ 正常郵件、🎲 隨機範例
- **範例選擇器**: 提供 10 個預設範例供快速測試
- **實時分類結果**: 清晰的垃圾郵件/正常郵件狀態顯示
- **置信度可視化**: 互動式機率條形圖
- **分類歷史記錄**: 自動保存最近 10 次分類結果
- **預處理展示**: 可選的文本預處理過程展示
- **批量測試**: 支持多封郵件的批量分類測試

### 📊 Model Performance - 模型性能分析
- **多模型比較**: 4 種機器學習算法性能對比
- **ROC 曲線**: 互動式 ROC 曲線圖表
- **Precision-Recall 曲線**: 詳細的 PR 曲線分析
- **混淆矩陣**: 可視化分類結果矩陣
- **性能指標**: 準確率、精確率、召回率、F1 分數、AUC
- **特徵重要性**: 模型特徵權重分析

### 📈 Data Visualization - 數據可視化
- **數據集概覽**: 總郵件數、垃圾郵件比例等統計
- **類別分布圖**: 垃圾郵件 vs 正常郵件數量分布
- **Top Tokens 分析**: 垃圾郵件和正常郵件的高頻詞彙對比
- **詞雲圖**: 視覺化詞彙分布
- **文本長度分布**: 不同類別郵件的長度統計

## 🚀 快速開始

### 1. 環境設置

```bash
# 克隆項目
git clone <repository-url>
cd spam-email-classifier

# 創建虛擬環境
python -m venv venv

# 激活虛擬環境
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 安裝依賴
pip install -r requirements.txt
```

### 2. 準備數據

確保數據集文件位於正確位置：
- `dataset/sms_spam_no_header.csv` - 原始垃圾郵件數據集
- `dataset/processed/sms_spam_clean.csv` - 處理過的數據集（可選）

**數據集格式**: CSV 文件，包含 `label` 和 `text` 兩列
- `label`: 'spam' 或 'ham'
- `text`: 郵件內容文本

### 3. 運行應用

```bash
streamlit run app.py
```

應用將在 `http://localhost:8501` 啟動。

### 快速檢查清單 ✅

在開始使用前，請確認：

- [x] Python 3.8+ 已安裝
- [x] 虛擬環境已創建並激活
- [x] 所有依賴已通過 `pip install -r requirements.txt` 安裝
- [x] 數據文件 `dataset/sms_spam_no_header.csv` 存在
- [x] 應用已通過 `streamlit run app.py` 啟動
- [x] 瀏覽器已打開 `http://localhost:8501`

### 首次使用建議 💡

1. **選擇快速模式 + 25% 數據集**進行首次測試（約 15-30 秒）
2. **訓練完成後先使用 Live Inference 頁面**測試基本功能
3. **嘗試不同的範例按鈕**體驗範例載入功能
4. **查看 Model Performance 頁面**了解模型性能
5. **探索 Data Visualization 頁面**了解數據特徵

## 📁 項目結構

```
spam-email-classifier/
├── app.py                     # 主應用文件
├── pages/                     # Streamlit 頁面模塊
│   ├── live_inference.py      # 實時推理頁面
│   ├── model_performance.py   # 模型性能頁面
│   └── data_visualization.py  # 數據可視化頁面
├── src/                       # 核心業務邏輯
│   ├── classifier.py          # 多模型分類器（支持快速/標準模式）
│   ├── data_loader.py         # 數據載入器
│   ├── preprocessing.py       # 文本預處理（支持 NLTK 和備用方案）
│   ├── visualizations.py      # 可視化函數（Plotly + Matplotlib）
│   └── config.py             # 應用配置和字體設置
├── dataset/                   # 數據文件
├── models/                    # 訓練好的模型
├── .streamlit/               # Streamlit 配置
├── requirements.txt          # Python 依賴
└── README.md                # 項目說明
```

## 🔧 使用說明

### 首次使用

1. **啟動應用**：運行 `streamlit run app.py`
2. **選擇訓練模式**：
   - ⚡ **快速模式**（推薦）：30-60 秒完成訓練
   - 🎯 **標準模式**：2-5 分鐘，更高準確率
3. **選擇數據集大小**：
   - 10% 數據集：5-15 秒（快速測試）
   - 25% 數據集：15-30 秒（開發調試）
   - 50% 數據集：30-60 秒（推薦）
   - 完整數據集：1-8 分鐘（最佳性能）
4. **訓練模型**：點擊側邊欄的「🚀 訓練模型」按鈕
5. **查看訓練狀態**：系統會顯示每個模型的訓練進度和結果
6. **開始使用**：訓練完成後即可使用所有功能

### 功能使用

#### Live Inference 頁面
- **輸入郵件**：在文本區域手動輸入或使用範例
- **快速範例**：
  - 🚨 垃圾郵件範例：隨機選擇垃圾郵件
  - ✅ 正常郵件範例：隨機選擇正常郵件
  - 🎲 隨機範例：從整個數據集隨機選擇
- **範例選擇器**：瀏覽 10 個預設範例並一鍵載入
- **分類按鈕**：🚀 開始分類 / 🗑️ 清空內容
- **結果展示**：清晰的分類結果、置信度和機率條形圖
- **歷史記錄**：查看最近 10 次分類結果
- **批量測試**：測試多封郵件並查看準確率

#### Model Performance 頁面
- 查看模型比較表格
- 分析 ROC 和 PR 曲線
- 檢視混淆矩陣
- 探索特徵重要性

#### Data Visualization 頁面
- 瀏覽數據集統計信息
- 查看類別分布
- 分析高頻詞彙
- 生成詞雲圖

## 🛠️ 技術棧

- **前端框架**: Streamlit（多頁面應用）
- **機器學習**: scikit-learn（4 種算法）
- **數據處理**: pandas, numpy
- **可視化**: Plotly（互動圖表）, Matplotlib, Seaborn, WordCloud
- **文本處理**: NLTK（支持備用方案）
- **配置管理**: 自定義配置系統，支持字體自動適配

## 🌟 特色功能

### 智能範例系統
- **隨機範例生成**: 從真實數據集中隨機選擇範例
- **範例選擇器**: 提供 10 個預設範例供快速測試
- **一鍵載入**: 點擊範例直接載入到輸入框
- **範例預覽**: 顯示範例的前 80 個字符

### 模型訓練優化
- **快速模式**: 針對速度優化的模型參數
- **進度顯示**: 實時顯示每個模型的訓練進度
- **錯誤處理**: 某個模型失敗不影響其他模型訓練
- **狀態監控**: 詳細的模型訓練狀態顯示

### 用戶體驗增強
- **Session State 管理**: 完善的狀態管理，避免數據丟失
- **動態界面**: 根據訓練狀態動態調整可用功能
- **分類歷史**: 自動記錄和展示分類歷史
- **字體適配**: 自動處理中文字體問題

### 可視化增強
- **互動圖表**: 使用 Plotly 提供豐富的互動功能
- **實時更新**: 圖表根據用戶選擇實時更新
- **多語言支持**: 圖表標題自動適配語言環境

## 📊 支持的模型

### 快速模式（推薦）
- **Naive Bayes**: MultinomialNB，適合文本分類
- **SVM**: 線性核函數，C=0.1，max_iter=500
- **Random Forest**: 30 棵樹，max_depth=8，並行處理
- **Logistic Regression**: liblinear 求解器，C=0.1

### 標準模式
- **Naive Bayes**: 默認參數配置
- **SVM**: 線性核函數，C=1.0，max_iter=1000
- **Random Forest**: 100 棵樹，max_depth=15
- **Logistic Regression**: liblinear 求解器，C=1.0

### 模型特點
- **訓練速度**: 快速模式比標準模式快 3-5 倍
- **準確率**: 標準模式通常有 1-3% 的準確率提升
- **資源消耗**: 快速模式使用更少的 CPU 和內存

## ⚙️ 配置選項

### 側邊欄設置
- **模型選擇**: 選擇用於分類的模型（只顯示已訓練成功的模型）
- **模型狀態詳情**: 查看每個模型的訓練狀態（✅ 成功 / ❌ 失敗）

### 高級設置
- **快速訓練模式**: 啟用以大幅減少訓練時間
- **數據集大小**: 選擇用於訓練的數據量（10%-100%）
- **分類閾值**: 調整垃圾郵件判定閾值（0.1-0.9）
- **最大特徵數**: 設置 TF-IDF 特徵數量（1000-10000）
- **停用詞處理**: 選擇是否移除英文停用詞

### 系統狀態
- **數據載入狀態**: 顯示數據集載入情況和統計信息
- **模型訓練狀態**: 顯示模型是否已就緒
- **預估訓練時間**: 根據配置顯示預計訓練時間

### 高級配置
編輯 `.streamlit/config.toml` 文件可以自定義：
- 主題顏色
- 端口設置
- 瀏覽器行為

## 🚀 部署到 Streamlit Cloud

1. **推送到 GitHub**：將代碼推送到 GitHub 倉庫
2. **連接 Streamlit Cloud**：訪問 [share.streamlit.io](https://share.streamlit.io)
3. **配置部署**：選擇倉庫和分支
4. **啟動應用**：等待部署完成
5. **訪問部屬**：訪問 [w5114056034-hw3-emailspamclassification.streamlit.app](https://w5114056034-hw3-emailspamclassification.streamlit.app/)

### 部署注意事項
- 確保 `requirements.txt` 包含所有依賴
- 數據文件大小不超過 GitHub 限制
- 考慮使用 Git LFS 處理大文件

## 🔍 故障排除

### 常見問題

**Q: 模型訓練失敗**
A: 
- 檢查數據文件 `dataset/sms_spam_no_header.csv` 是否存在
- 嘗試使用更小的數據集（10% 或 25%）
- 確保有足夠的內存（建議 4GB+）
- 查看側邊欄的模型狀態詳情了解具體哪些模型失敗

**Q: 某些模型訓練失敗（如 Logistic Regression 或 Random Forest）**
A:
- 這是正常現象，系統會跳過失敗的模型繼續訓練其他模型
- 可以使用成功訓練的模型進行分類
- 嘗試快速模式以提高訓練成功率

**Q: 範例按鈕沒有反應**
A:
- 確保已完成模型訓練
- 檢查瀏覽器控制台是否有錯誤
- 嘗試刷新頁面重新載入

**Q: 頁面載入緩慢**
A: 
- 首次載入需要下載 NLTK 數據，請耐心等待
- 如果 NLTK 下載失敗，系統會自動使用備用方案

**Q: 中文字體警告**
A: 
- 系統已自動處理字體問題，警告不影響功能
- 圖表標題會自動使用英文以避免字體問題

**Q: 可視化圖表不顯示**
A: 
- 確保安裝了所有可視化依賴庫
- 檢查 Plotly 和 Matplotlib 版本是否兼容

**Q: 部署到 Streamlit Cloud 失敗**
A: 
- 檢查 requirements.txt 包含所有必要依賴
- 確保數據文件大小不超過 GitHub 限制
- 檢查文件路徑是否正確

### 性能優化

- **緩存機制**: 使用 `@st.cache_data` 緩存數據載入，`@st.cache_resource` 緩存模型
- **快速模式**: 啟用快速訓練模式可減少 60-80% 的訓練時間
- **數據集採樣**: 使用較小的數據集進行快速測試和開發
- **特徵數量**: 減少 TF-IDF 特徵數量可提高訓練和預測速度
- **模型選擇**: Naive Bayes 和 Logistic Regression 通常比 SVM 和 Random Forest 更快
- **Session State**: 優化的 session state 管理避免不必要的重新計算

## 📈 性能指標

### 分類性能
- **準確率目標**: > 90%（快速模式），> 95%（標準模式）
- **響應時間**: < 500ms（單封郵件分類）
- **支持數據量**: 10K+ 郵件

### 訓練時間（基於數據集大小）
- **10% 數據集**: 5-15 秒（快速模式），15-30 秒（標準模式）
- **25% 數據集**: 15-30 秒（快速模式），30-90 秒（標準模式）
- **50% 數據集**: 30-60 秒（快速模式），1-3 分鐘（標準模式）
- **完整數據集**: 1-2 分鐘（快速模式），3-8 分鐘（標準模式）

### 系統要求
- **內存**: 建議 4GB+ RAM
- **CPU**: 多核心處理器（支持並行訓練）
- **存儲**: 100MB+ 可用空間

## 🤝 貢獻指南

1. Fork 項目
2. 創建功能分支
3. 提交更改
4. 推送到分支
5. 創建 Pull Request

## 使用流程(./LIVE_INFERENCE_FEATURES.md)

## 📄 許可證

MIT License

## 📞 聯繫方式

如有問題或建議，請通過以下方式聯繫：
- 創建 GitHub Issue
- 發送郵件至 [w114056034@mail.nchu.edu.tw]

---

**垃圾郵件分類系統 - Phase 1** | 基於 Streamlit 和 scikit-learn 構建 | © 2025
