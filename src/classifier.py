"""
å¤šæ¨¡å‹åˆ†é¡å™¨æ¨¡å¡Š
æ”¯æŒå¤šç¨®æ©Ÿå™¨å­¸ç¿’ç®—æ³•é€²è¡Œåƒåœ¾éƒµä»¶åˆ†é¡
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import streamlit as st
import joblib
import os
from datetime import datetime

# æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# è©•ä¼°æŒ‡æ¨™
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve,
    classification_report
)
from sklearn.model_selection import cross_val_score

# å°å…¥è‡ªå®šç¾©æ¨¡å¡Š
from .preprocessing import TextPreprocessor
from .data_loader import DataLoader

class MultiModelClassifier:
    """å¤šæ¨¡å‹åˆ†é¡å™¨é¡"""
    
    def __init__(self, fast_mode: bool = True):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹åˆ†é¡å™¨
        
        Args:
            fast_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆå„ªåŒ–è¨“ç·´é€Ÿåº¦ï¼‰
        """
        if fast_mode:
            # å¿«é€Ÿæ¨¡å¼ï¼šå„ªåŒ–é€Ÿåº¦
            self.models = {
                'Naive Bayes': MultinomialNB(),
                'SVM': SVC(
                    kernel='linear',  # ç·šæ€§æ ¸å‡½æ•¸æœ€å¿«
                    probability=True, 
                    random_state=42,
                    C=0.1,  # è¼ƒå°çš„ C å€¼åŠ å¿«è¨“ç·´
                    max_iter=500
                ),
                'Random Forest': RandomForestClassifier(
                    n_estimators=30,  # æ¸›å°‘æ¨¹çš„æ•¸é‡
                    random_state=42,
                    n_jobs=-1,
                    max_depth=8,
                    min_samples_split=10
                ),
                'Logistic Regression': LogisticRegression(
                    random_state=42, 
                    max_iter=500,
                    solver='liblinear',
                    C=0.1
                )
            }
        else:
            # æ¨™æº–æ¨¡å¼ï¼šå¹³è¡¡é€Ÿåº¦å’Œæ€§èƒ½
            self.models = {
                'Naive Bayes': MultinomialNB(),
                'SVM': SVC(
                    kernel='linear',
                    probability=True, 
                    random_state=42,
                    C=1.0,
                    max_iter=1000
                ),
                'Random Forest': RandomForestClassifier(
                    n_estimators=100,
                    random_state=42,
                    n_jobs=-1,
                    max_depth=15
                ),
                'Logistic Regression': LogisticRegression(
                    random_state=42, 
                    max_iter=1000,
                    solver='liblinear',
                    C=1.0
                )
            }
        
        self.trained_models = {}
        self.preprocessor = TextPreprocessor()
        self.data_loader = DataLoader()
        self.model_performance = {}
        self.is_trained = False
        self.fast_mode = fast_mode
    
    def get_trained_models(self) -> List[str]:
        """ç²å–å·²è¨“ç·´çš„æ¨¡å‹åˆ—è¡¨"""
        return list(self.trained_models.keys())
    
    def get_model_status(self) -> Dict[str, bool]:
        """ç²å–æ‰€æœ‰æ¨¡å‹çš„è¨“ç·´ç‹€æ…‹"""
        status = {}
        for model_name in self.models.keys():
            status[model_name] = model_name in self.trained_models
        return status
        
    def train_models(self, X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray):
        """è¨“ç·´æ‰€æœ‰æ¨¡å‹"""
        self.trained_models = {}
        self.model_performance = {}
        
        # å‰µå»ºé€²åº¦æ¢
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_models = len(self.models)
        
        for i, (name, model) in enumerate(self.models.items()):
            try:
                status_text.text(f'æ­£åœ¨è¨“ç·´ {name} æ¨¡å‹... ({i+1}/{total_models})')
                
                # è¨“ç·´æ¨¡å‹
                model.fit(X_train, y_train)
                self.trained_models[name] = model
                
                # é æ¸¬
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
                
                # è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
                performance = {
                    'accuracy': accuracy_score(y_test, y_pred),
                    'precision': precision_score(y_test, y_pred, pos_label='spam'),
                    'recall': recall_score(y_test, y_pred, pos_label='spam'),
                    'f1': f1_score(y_test, y_pred, pos_label='spam'),
                    'auc': roc_auc_score(y_test == 'spam', y_pred_proba),
                    'y_pred': y_pred,
                    'y_pred_proba': y_pred_proba,
                    'y_test': y_test
                }
                
                # ç°¡åŒ–äº¤å‰é©—è­‰ï¼ˆæ¸›å°‘ CV æŠ˜æ•¸ä»¥åŠ å¿«é€Ÿåº¦ï¼‰
                cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')
                performance['cv_mean'] = cv_scores.mean()
                performance['cv_std'] = cv_scores.std()
                
                self.model_performance[name] = performance
                
                # æ›´æ–°é€²åº¦
                progress_bar.progress((i + 1) / total_models)
                st.success(f"âœ… {name} è¨“ç·´å®Œæˆ - æº–ç¢ºç‡: {performance['accuracy']:.3f}")
                

                
            except Exception as e:
                st.error(f"âŒ {name} è¨“ç·´å¤±æ•—: {str(e)}")
                # è¨˜éŒ„å¤±æ•—çš„æ¨¡å‹ï¼Œä½†ç¹¼çºŒè¨“ç·´å…¶ä»–æ¨¡å‹
                st.warning(f"è·³é {name} æ¨¡å‹ï¼Œç¹¼çºŒè¨“ç·´å…¶ä»–æ¨¡å‹...")
                continue
        
        # æ¸…ç†é€²åº¦é¡¯ç¤º
        progress_bar.empty()
        status_text.empty()
        
        # æª¢æŸ¥è¨“ç·´çµæœ
        total_models = len(self.models)
        successful_models = len(self.trained_models)
        
        if successful_models > 0:
            self.is_trained = True
            st.success(f"ğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆï¼æˆåŠŸè¨“ç·´äº† {successful_models}/{total_models} å€‹æ¨¡å‹")
            
            if successful_models < total_models:
                failed_models = set(self.models.keys()) - set(self.trained_models.keys())
                st.warning(f"âš ï¸ ä»¥ä¸‹æ¨¡å‹è¨“ç·´å¤±æ•—: {', '.join(failed_models)}")
        else:
            st.error("âŒ æ‰€æœ‰æ¨¡å‹è¨“ç·´å¤±æ•—ï¼è«‹æª¢æŸ¥æ•¸æ“šå’Œé…ç½®ã€‚")
            self.is_trained = False
    
    def predict(self, text: str, model_name: str = 'Naive Bayes') -> Dict[str, Any]:
        """é æ¸¬å–®å€‹æ–‡æœ¬"""
        # è©³ç´°çš„éŒ¯èª¤æª¢æŸ¥
        if not self.is_trained:
            return {
                'is_spam': False,
                'confidence': 0.0,
                'spam_probability': 0.0,
                'processing_time': 0.0,
                'error': 'æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆè¨“ç·´æ¨¡å‹'
            }
        
        if model_name not in self.trained_models:
            available_models = list(self.trained_models.keys())
            return {
                'is_spam': False,
                'confidence': 0.0,
                'spam_probability': 0.0,
                'processing_time': 0.0,
                'error': f'æ¨¡å‹ "{model_name}" ä¸å­˜åœ¨ã€‚å¯ç”¨æ¨¡å‹: {available_models}'
            }
        
        start_time = datetime.now()
        
        try:
            # é è™•ç†æ–‡æœ¬
            processed_text = self.preprocessor.preprocess_text(text)
            
            # ç‰¹å¾µæå–
            features = self.preprocessor.extract_tfidf_features([processed_text])
            
            # é æ¸¬
            model = self.trained_models[model_name]
            prediction = model.predict(features)[0]
            probabilities = model.predict_proba(features)[0]
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # ç²å–åƒåœ¾éƒµä»¶æ©Ÿç‡
            spam_prob = probabilities[1] if len(probabilities) > 1 else probabilities[0]
            
            return {
                'is_spam': prediction == 'spam',
                'confidence': max(probabilities),
                'spam_probability': spam_prob,
                'processing_time': processing_time,
                'processed_text': processed_text,
                'model_used': model_name
            }
            
        except Exception as e:
            return {
                'is_spam': False,
                'confidence': 0.0,
                'spam_probability': 0.0,
                'processing_time': 0.0,
                'error': str(e)
            }
    
    def get_model_comparison(self) -> pd.DataFrame:
        """ç²å–æ¨¡å‹æ¯”è¼ƒè¡¨æ ¼"""
        if not self.model_performance:
            return pd.DataFrame()
        
        comparison_data = []
        for name, perf in self.model_performance.items():
            comparison_data.append({
                'Model': name,
                'Accuracy': f"{perf['accuracy']:.4f}",
                'Precision': f"{perf['precision']:.4f}",
                'Recall': f"{perf['recall']:.4f}",
                'F1-Score': f"{perf['f1']:.4f}",
                'AUC': f"{perf['auc']:.4f}",
                'CV Mean': f"{perf['cv_mean']:.4f}",
                'CV Std': f"{perf['cv_std']:.4f}"
            })
        
        return pd.DataFrame(comparison_data)
    
    def get_roc_data(self) -> Dict[str, Dict]:
        """ç²å– ROC æ›²ç·šæ•¸æ“š"""
        roc_data = {}
        
        for name, perf in self.model_performance.items():
            y_test_binary = (perf['y_test'] == 'spam').astype(int)
            fpr, tpr, _ = roc_curve(y_test_binary, perf['y_pred_proba'])
            
            roc_data[name] = {
                'fpr': fpr,
                'tpr': tpr,
                'auc': perf['auc']
            }
        
        return roc_data
    
    def get_pr_data(self) -> Dict[str, Dict]:
        """ç²å– Precision-Recall æ›²ç·šæ•¸æ“š"""
        pr_data = {}
        
        for name, perf in self.model_performance.items():
            y_test_binary = (perf['y_test'] == 'spam').astype(int)
            precision, recall, _ = precision_recall_curve(y_test_binary, perf['y_pred_proba'])
            
            pr_data[name] = {
                'precision': precision,
                'recall': recall
            }
        
        return pr_data
    
    def get_confusion_matrix_data(self, model_name: str) -> np.ndarray:
        """ç²å–æ··æ·†çŸ©é™£æ•¸æ“š"""
        if model_name not in self.model_performance:
            return np.array([])
        
        perf = self.model_performance[model_name]
        return confusion_matrix(perf['y_test'], perf['y_pred'])
    
    def save_models(self, filepath: str = "models/trained_models.pkl"):
        """ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not self.is_trained:
            st.warning("æ²’æœ‰è¨“ç·´å¥½çš„æ¨¡å‹å¯ä»¥ä¿å­˜")
            return False
        
        try:
            # ç¢ºä¿ç›®éŒ„å­˜åœ¨
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # ä¿å­˜æ¨¡å‹å’Œé è™•ç†å™¨
            model_data = {
                'trained_models': self.trained_models,
                'preprocessor': self.preprocessor,
                'model_performance': self.model_performance,
                'timestamp': datetime.now().isoformat()
            }
            
            joblib.dump(model_data, filepath)
            st.success(f"æ¨¡å‹å·²ä¿å­˜åˆ° {filepath}")
            return True
            
        except Exception as e:
            st.error(f"ä¿å­˜æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def load_models(self, filepath: str = "models/trained_models.pkl"):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        try:
            if not os.path.exists(filepath):
                st.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                return False
            
            model_data = joblib.load(filepath)
            
            self.trained_models = model_data['trained_models']
            self.preprocessor = model_data['preprocessor']
            self.model_performance = model_data['model_performance']
            self.is_trained = True
            
            st.success(f"æ¨¡å‹å·²å¾ {filepath} è¼‰å…¥")
            return True
            
        except Exception as e:
            st.error(f"è¼‰å…¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def get_feature_importance(self, model_name: str, n_features: int = 20) -> List[Tuple[str, float]]:
        """ç²å–ç‰¹å¾µé‡è¦æ€§"""
        if model_name not in self.trained_models:
            return []
        
        model = self.trained_models[model_name]
        feature_names = self.preprocessor.get_feature_names()
        
        if hasattr(model, 'feature_importances_'):
            # Random Forest
            importances = model.feature_importances_
        elif hasattr(model, 'coef_'):
            # Logistic Regression, SVM
            importances = np.abs(model.coef_[0])
        else:
            # Naive Bayes
            importances = np.abs(model.feature_log_prob_[1] - model.feature_log_prob_[0])
        
        # ç²å–å‰ n å€‹é‡è¦ç‰¹å¾µ
        feature_importance = list(zip(feature_names, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        return feature_importance[:n_features]